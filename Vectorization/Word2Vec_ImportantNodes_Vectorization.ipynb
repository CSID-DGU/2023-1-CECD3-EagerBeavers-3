{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "## using graphviz\n",
        "!apt-get -qq install -y graphviz && pip install -q pydot\n",
        "import pydot\n",
        "## 아래 있는것은 필수는 아닌데, 가끔 에러가 생길 때가 있어서, 그냥 같이 해줌.\n",
        "!apt-get install graphviz libgraphviz-dev pkg-config\n",
        "!pip install pygraphviz\n",
        "import pygraphviz"
      ],
      "metadata": {
        "id": "TE68kHjYsUlP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zmbiHrZJxMZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "QfANLMLds2Ci"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ggd00GgAo_i_"
      },
      "outputs": [],
      "source": [
        "from gensim.models import Word2Vec\n",
        "import networkx as nx\n",
        "import pygraphviz as pgv\n",
        "from random import shuffle\n",
        "\n",
        "dot_filename = \"/content/drive/MyDrive/0-cpg.dot\"  # 실제 DOT 파일의 경로\n",
        "\n",
        "# DOT 파일 파싱 및 그래프 생성 함수\n",
        "def parse_dot_file(dot_filename):\n",
        "    graph = pgv.AGraph(dot_filename)\n",
        "    cpg_graph = nx.DiGraph()\n",
        "\n",
        "    for edge in graph.edges():\n",
        "        source = edge[0]\n",
        "        target = edge[1]\n",
        "        cpg_graph.add_edge(source, target)\n",
        "\n",
        "    return cpg_graph\n",
        "\n",
        "# DOT 파일 파싱 및 그래프 생성\n",
        "cpg_graph = parse_dot_file(dot_filename)\n",
        "\n",
        "# Betweenness Centrality 계산\n",
        "betweenness_centrality = nx.betweenness_centrality(cpg_graph)\n",
        "\n",
        "# 중요도가 큰 순서대로 노드 정렬\n",
        "sorted_nodes = sorted(betweenness_centrality, key=betweenness_centrality.get, reverse=True)\n",
        "\n",
        "# 랜덤 워크 생성 함수\n",
        "def generate_random_walks(graph, num_walks, walk_length):\n",
        "    walks = []\n",
        "    for _ in range(num_walks):\n",
        "        shuffle(sorted_nodes)  # 중요도가 큰 순서대로 섞음\n",
        "        for node in sorted_nodes:\n",
        "            walk = [node]\n",
        "            current_node = node\n",
        "            for _ in range(walk_length - 1):\n",
        "                neighbors = list(graph.neighbors(current_node))\n",
        "                if neighbors:\n",
        "                    next_node = neighbors[0]\n",
        "                    walk.append(next_node)\n",
        "                    current_node = next_node\n",
        "                else:\n",
        "                    break\n",
        "            walks.append(walk)\n",
        "    return walks\n",
        "\n",
        "# 랜덤 워크 생성\n",
        "num_walks = 10\n",
        "walk_length = 5\n",
        "random_walks = generate_random_walks(cpg_graph, num_walks, walk_length)\n",
        "\n",
        "# Word2Vec 모델 학습\n",
        "model = Word2Vec(sentences=random_walks, vector_size=128, window=3, min_count=1, sg=1, workers=4, epochs=50)\n",
        "\n",
        "# 중요한 노드에 대한 벡터 확인\n",
        "most_important_node = sorted_nodes[0]\n",
        "embedding_vector = model.wv[str(most_important_node)]\n",
        "print(\"Most important node:\", most_important_node)\n",
        "print(\"Vector:\", embedding_vector)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "LTwL_RN1uaE6"
      }
    }
  ]
}