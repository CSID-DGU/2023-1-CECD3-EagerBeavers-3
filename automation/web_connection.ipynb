{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CSID-DGU/2023-1-CECD3-EagerBeavers-3/blob/main/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ihD2rEAjdWjh",
        "outputId": "8d211516-e77c-4587-df12-3d999b9e3c48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.11.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2023.11.17)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.2.0)\n",
            "Requirement already satisfied: pytorch-tabnet in /usr/local/lib/python3.10/dist-packages (4.1.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.23.5)\n",
            "Requirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.2.2)\n",
            "Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (2.1.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (4.66.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3->pytorch-tabnet) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3->pytorch-tabnet) (1.3.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.11.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2023.11.17)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.2.0)\n",
            "Requirement already satisfied: pytorch-tabnet in /usr/local/lib/python3.10/dist-packages (4.1.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.23.5)\n",
            "Requirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.2.2)\n",
            "Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (2.1.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (4.66.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3->pytorch-tabnet) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3->pytorch-tabnet) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "import networkx as nx\n",
        "import pandas as pd\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "!pip install torch_geometric\n",
        "!pip install pytorch-tabnet\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.data import Data\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "!pip install torch\n",
        "\n",
        "!pip install torch_geometric\n",
        "!pip install pytorch-tabnet\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import global_mean_pool\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cMgs5-xaZrqt"
      },
      "outputs": [],
      "source": [
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.data import Data\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "class CPGPredictDataset(Dataset):\n",
        "    def __init__(self, csv_file):\n",
        "        super(CPGPredictDataset, self).__init__()\n",
        "\n",
        "        self.df = pd.read_csv(csv_file)\n",
        "        self.df.fillna(0, inplace=True)\n",
        "\n",
        "        self.wo_cpgs_df = self.df.drop(columns=['index', 'nodes', 'edges', 'time'])\n",
        "        self.wo_cpgs_df = torch.tensor(self.wo_cpgs_df.values.astype(np.float32))\n",
        "\n",
        "        self.graph_list = self.cpgs2graph(self.df['nodes'], self.df['edges'])\n",
        "\n",
        "        self.label_encoder = LabelEncoder()\n",
        "\n",
        "        all_features = []\n",
        "        for idx in range(len(self.graph_list)):\n",
        "            graph_data = self.graph_list[idx]\n",
        "            features = [data['feature'] for _, data in graph_data.nodes(data=True)]\n",
        "            all_features.extend(features)\n",
        "\n",
        "        self.label_encoder.fit(all_features)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.graph_list)\n",
        "\n",
        "    def cpgs2graph_single(self, nodes, edges):\n",
        "        # 노드 및 엣지 정보 추출\n",
        "        nodes_info = [node.split(':') for node in nodes.split('|') if node]\n",
        "\n",
        "        if isinstance(edges, str):\n",
        "            edges_info = [edge.split('->') for edge in edges.split('|') if edge]\n",
        "        elif isinstance(edges, int):\n",
        "            edges_info = []\n",
        "        else:\n",
        "            raise ValueError(\"Invalid type for 'edges'. Should be either str or int.\")\n",
        "\n",
        "        # 그래프 생성\n",
        "        G = nx.Graph()\n",
        "\n",
        "        # 노드 추가\n",
        "        for node_info in nodes_info:\n",
        "            if len(node_info) > 1:  # 노드 정보가 제대로 있다면\n",
        "                G.add_node(node_info[0], feature=node_info[1])\n",
        "\n",
        "        # 엣지 추가\n",
        "        for edge_info in edges_info:\n",
        "            # 엣지 특성을 추가\n",
        "            if len(edge_info) > 1:\n",
        "                source, target_feature = edge_info[0], edge_info[1].split(':')\n",
        "                if len(target_feature) > 1:\n",
        "                    target, feature = target_feature[0], target_feature[1]\n",
        "                    G.add_edge(source, target, feature=feature)\n",
        "                else:\n",
        "                    print(\"Error: Edge feature is missing.\")\n",
        "            else:\n",
        "                print(\"Error: Incomplete edge information.\")\n",
        "\n",
        "        return G\n",
        "\n",
        "\n",
        "    def cpgs2graph(self, nodes_list, edges_list):\n",
        "        print('Convert \"CPG\"csv to graph')\n",
        "\n",
        "        graph_list = []\n",
        "        for nodes, edges in zip(nodes_list, edges_list):\n",
        "            try:\n",
        "                # 노드와 엣지를 그래프로 변환\n",
        "                G = self.cpgs2graph_single(nodes, edges)\n",
        "                graph_list.append(G)\n",
        "            except Exception as e:\n",
        "                print(f\"Error creating graph: {e}\")\n",
        "\n",
        "        print('Complete!')\n",
        "        return graph_list\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        graph_data = self.graph_list[idx]\n",
        "\n",
        "        nodes_info = [(node, self.label_encoder.transform([data['feature']])[0]) for node, data in graph_data.nodes(data=True)]\n",
        "        edges_info = [(u, v, data['feature']) for u, v, data in graph_data.edges(data=True)]\n",
        "\n",
        "        node_indices = [node[0] for node in nodes_info]\n",
        "        edges = [(node_indices.index(u), node_indices.index(v)) for u, v, _ in edges_info]\n",
        "\n",
        "        # edge_index 텐서 생성\n",
        "        edge_index = torch.tensor(list(zip(*edges)), dtype=torch.long)\n",
        "\n",
        "        # node feature 텐서 생성\n",
        "        x = torch.tensor([node[1] for node in nodes_info], dtype=torch.float).view(-1, 1)\n",
        "\n",
        "        data = Data(x=x, edge_index=edge_index)\n",
        "\n",
        "        return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rOPQQTs9R9zm"
      },
      "outputs": [],
      "source": [
        "class CPGPredictDataset(Dataset):\n",
        "    def __init__(self, csv_file):\n",
        "        super(CPGPredictDataset, self).__init__()\n",
        "\n",
        "        self.df = pd.read_csv(csv_file)\n",
        "        self.df.fillna(0, inplace=True)\n",
        "\n",
        "        self.wo_cpgs_df = self.df.drop(columns=['index', 'nodes', 'edges'])\n",
        "        self.wo_cpgs_df = torch.tensor(self.wo_cpgs_df.values.astype(np.float32))\n",
        "\n",
        "        self.graph_list = self.cpgs2graph(self.df['nodes'], self.df['edges'])\n",
        "\n",
        "        self.label_encoder = LabelEncoder()\n",
        "\n",
        "        all_features = []\n",
        "        for idx in range(len(self.graph_list)):\n",
        "            graph_data = self.graph_list[idx]\n",
        "            features = [data['feature'] for _, data in graph_data.nodes(data=True)]\n",
        "            all_features.extend(features)\n",
        "\n",
        "        self.label_encoder.fit(all_features)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.graph_list)\n",
        "\n",
        "    def cpgs2graph_single(self, nodes, edges):\n",
        "        # 노드 및 엣지 정보 추출\n",
        "        nodes_info = [node.split(':') for node in nodes.split('|') if node]\n",
        "\n",
        "        if isinstance(edges, str):\n",
        "            edges_info = [edge.split('->') for edge in edges.split('|') if edge]\n",
        "        elif isinstance(edges, int):\n",
        "            edges_info = []\n",
        "        else:\n",
        "            raise ValueError(\"Invalid type for 'edges'. Should be either str or int.\")\n",
        "\n",
        "        # 그래프 생성\n",
        "        G = nx.Graph()\n",
        "\n",
        "        # 노드 추가\n",
        "        for node_info in nodes_info:\n",
        "            if len(node_info) > 1:  # 노드 정보가 제대로 있다면\n",
        "                G.add_node(node_info[0], feature=node_info[1])\n",
        "\n",
        "        # 엣지 추가\n",
        "        for edge_info in edges_info:\n",
        "            # 엣지 특성을 추가\n",
        "            if len(edge_info) > 1:\n",
        "                source, target_feature = edge_info[0], edge_info[1].split(':')\n",
        "                if len(target_feature) > 1:\n",
        "                    target, feature = target_feature[0], target_feature[1]\n",
        "                    G.add_edge(source, target, feature=feature)\n",
        "                else:\n",
        "                    print(\"Error: Edge feature is missing.\")\n",
        "            else:\n",
        "                print(\"Error: Incomplete edge information.\")\n",
        "\n",
        "        return G\n",
        "\n",
        "\n",
        "    def cpgs2graph(self, nodes_list, edges_list):\n",
        "        print('Convert \"CPG\"csv to graph')\n",
        "\n",
        "        graph_list = []\n",
        "        for nodes, edges in zip(nodes_list, edges_list):\n",
        "            try:\n",
        "                # 노드와 엣지를 그래프로 변환\n",
        "                G = self.cpgs2graph_single(nodes, edges)\n",
        "                graph_list.append(G)\n",
        "            except Exception as e:\n",
        "                print(f\"Error creating graph: {e}\")\n",
        "\n",
        "        print('Complete!')\n",
        "        return graph_list\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        graph_data = self.graph_list[idx]\n",
        "\n",
        "        nodes_info = [(node, self.label_encoder.transform([data['feature']])[0]) for node, data in graph_data.nodes(data=True)]\n",
        "        edges_info = [(u, v, data['feature']) for u, v, data in graph_data.edges(data=True)]\n",
        "\n",
        "        node_indices = [node[0] for node in nodes_info]\n",
        "        edges = [(node_indices.index(u), node_indices.index(v)) for u, v, _ in edges_info]\n",
        "\n",
        "        # edge_index 텐서 생성\n",
        "        edge_index = torch.tensor(list(zip(*edges)), dtype=torch.long)\n",
        "\n",
        "        # node feature 텐서 생성\n",
        "        x = torch.tensor([node[1] for node in nodes_info], dtype=torch.float).view(-1, 1)\n",
        "\n",
        "        data = Data(x=x, edge_index=edge_index)\n",
        "\n",
        "        return data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OSutwTFzfnie"
      },
      "outputs": [],
      "source": [
        "num_node_features = 1  # 노드 피처의 차원\n",
        "\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, num_node_features):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GCNConv(num_node_features, 16)\n",
        "        self.conv2 = GCNConv(16, 1)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, training=self.training)\n",
        "\n",
        "        x = self.conv2(x, edge_index)\n",
        "\n",
        "        x = global_mean_pool(x, data.batch)\n",
        "\n",
        "        return x.view(-1)\n",
        "\n",
        "#예측 결과 출력 함수\n",
        "def interpret_prediction(prediction):\n",
        "    # numpy.round를 사용하여 소수점 3자리에서 반올림\n",
        "    rounded_pred = np.round(prediction, 3)\n",
        "\n",
        "    # 소수점 이하 3자리까지만 출력하도록 문자열 형식으로 변환\n",
        "    rounded_pred_str = f\"{rounded_pred:.3f}\"\n",
        "    # 범위에 따른 문자열 반환\n",
        "    # if 0 <= rounded_pred <= 0.5:\n",
        "    #     return f\"constant in Big-O Notation, predicted value was : {rounded_pred}\"\n",
        "    # elif 0.6 <= rounded_pred <= 1.5:\n",
        "    #     return f\"logn in Big-O Notation, predicted value was : {rounded_pred}\"\n",
        "    # elif 1.6 <= rounded_pred <= 2.5:\n",
        "    #     return f\"linear in Big-O Notation, predicted value was : {rounded_pred}\"\n",
        "    # elif 2.6 <= rounded_pred <= 3.5:\n",
        "    #     return f\"nlogn in Big-O Notation, predicted value was : {rounded_pred}\"\n",
        "    # elif 3.6 <= rounded_pred <= 4.5:\n",
        "    #     return f\"quadratic in Big-O Notation, predicted value was : {rounded_pred}\"\n",
        "    # else:\n",
        "    #     return f\"bigger than quadratic in Big-O Notation, predicted value was : {rounded_pred}\"\n",
        "    return float(rounded_pred_str)\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqFmSEbmeKDg"
      },
      "source": [
        "# CPG 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W0TeEpbQddkQ"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "def execute_script(script_path):\n",
        "    # 권한 부여하기\n",
        "    os.system('chmod +x {}'.format(script_path))\n",
        "    # 실행하기\n",
        "    os.system('sh {}'.format(script_path))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PfO_FlPTeHVT"
      },
      "source": [
        "# csv 생성 함수"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uz7IP6YBeGI7"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "\n",
        "def process_all_dot_files(folder_path, output_csv_path):\n",
        "    for file_name in os.listdir(folder_path):\n",
        "        if file_name.endswith(\".dot\"):\n",
        "            file_path = os.path.join(folder_path, file_name)\n",
        "            print(f\"Processing file: {file_name}\")\n",
        "            try:\n",
        "                nodes_and_edges = extract_node_and_edge_info(file_path)\n",
        "                write_to_csv(file_name, nodes_and_edges, output_csv_path)\n",
        "            except IOError as e:\n",
        "                print(f\"Error processing file {file_name}: {e}\")\n",
        "\n",
        "def extract_node_and_edge_info(file_path):\n",
        "    nodes = []\n",
        "    edges = []\n",
        "\n",
        "    with open(file_path, 'r') as file:\n",
        "        dot_content = file.read()\n",
        "\n",
        "        # Extract and print labels\n",
        "        node_pattern = re.compile(r'\"(\\d+)\"\\s*\\[label\\s*=\\s*<\\s*\\(([^,]+)')\n",
        "        node_matches = node_pattern.findall(dot_content)\n",
        "\n",
        "        for node_match in node_matches:\n",
        "            node_number, literal_value = node_match\n",
        "            node = f\"{node_number}:{literal_value}\"\n",
        "            nodes.append(node)\n",
        "\n",
        "        # Extract and print edge information\n",
        "        edge_pattern = re.compile(r'\"(\\S+)\"\\s*->\\s*\"(\\S+)\"\\s*\\[\\s*label\\s*=\\s*\"([^\"]+)\"\\s*\\]')\n",
        "        edge_matches = edge_pattern.findall(dot_content)\n",
        "\n",
        "        for edge_match in edge_matches:\n",
        "            source_node, target_node, label = edge_match\n",
        "            cleaned_label = label.rstrip(':').strip()\n",
        "            edge = f\"{source_node}->{target_node}:{cleaned_label}\"\n",
        "            edges.append(edge)\n",
        "\n",
        "    return '|'.join(nodes) + \"$\" + '|'.join(edges)\n",
        "\n",
        "def write_to_csv_header(output_csv_path):\n",
        "    with open(output_csv_path, 'w') as csv_file:\n",
        "        # Write CSV header\n",
        "        csv_file.write(\"index,nodes,edges,time\\n\")\n",
        "\n",
        "def write_to_csv(file_name, nodes_and_edges, output_csv_path):\n",
        "    cleaned_file_name = extract_numeric_part(file_name)\n",
        "\n",
        "    # Split nodes and edges using \"|\"\n",
        "    parts = nodes_and_edges.split(\"$\")\n",
        "\n",
        "    if len(parts) == 2:\n",
        "        # Write file name, nodes, and edges to CSV\n",
        "        with open(output_csv_path, 'a') as csv_file:\n",
        "            csv_file.write(f\"{cleaned_file_name},\\\"{parts[0]}\\\",\\\"{parts[1]}\\\"\\n\")\n",
        "    else:\n",
        "        # Handle the case when the format is unexpected\n",
        "        with open(output_csv_path, 'a') as csv_file:\n",
        "            csv_file.write(\"\\\"\\\",\\\"\\\",{nodes_and_edges}\\n\")\n",
        "\n",
        "def extract_numeric_part(file_name):\n",
        "    pattern = re.compile(r'\\d+')\n",
        "    match = pattern.search(file_name)\n",
        "\n",
        "    if match:\n",
        "        return match.group()\n",
        "\n",
        "    return \"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qyl8QUGfQtfJ",
        "outputId": "884148ac-bdb2-44ba-f093-8e237dd7e1c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (2.2.5)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from flask) (3.0.1)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from flask) (3.1.2)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from flask) (2.1.2)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from flask) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->flask) (2.1.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install flask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fb_idTyVPSje",
        "outputId": "b3095635-7f79-4ded-d83a-b82236083c58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BxB7ePdfSidU",
        "outputId": "d654cb67-4169-4405-e588-7d7135541af6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: flask_ngrok in /usr/local/lib/python3.10/dist-packages (0.0.25)\n",
            "Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.10/dist-packages (from flask_ngrok) (2.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from flask_ngrok) (2.31.0)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask_ngrok) (3.0.1)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask_ngrok) (3.1.2)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask_ngrok) (2.1.2)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.8->flask_ngrok) (8.1.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->flask_ngrok) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->flask_ngrok) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->flask_ngrok) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->flask_ngrok) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->Flask>=0.8->flask_ngrok) (2.1.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install flask_ngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xcfte7PvZt5w",
        "outputId": "a2a1ec82-1c20-487e-d4b6-d08760175ba4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ngrok in /usr/local/lib/python3.10/dist-packages (0.12.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install ngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KQ00kymZk2X",
        "outputId": "35e5bba5-f0a9-4a84-ed71-68bf37ca6a84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2023-12-16 16:50:33--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
            "Resolving bin.equinox.io (bin.equinox.io)... 52.202.168.65, 54.161.241.46, 18.205.222.128, ...\n",
            "Connecting to bin.equinox.io (bin.equinox.io)|52.202.168.65|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13921656 (13M) [application/octet-stream]\n",
            "Saving to: ‘ngrok-stable-linux-amd64.zip.3’\n",
            "\n",
            "ngrok-stable-linux- 100%[===================>]  13.28M  49.9MB/s    in 0.3s    \n",
            "\n",
            "2023-12-16 16:50:33 (49.9 MB/s) - ‘ngrok-stable-linux-amd64.zip.3’ saved [13921656/13921656]\n",
            "\n",
            "Archive:  ngrok-stable-linux-amd64.zip\n",
            "replace ngrok? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n",
            "Authtoken saved to configuration file: /root/.ngrok2/ngrok.yml\n"
          ]
        }
      ],
      "source": [
        "!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip\n",
        "!unzip ngrok-stable-linux-amd64.zip\n",
        "!cp ngrok /usr/local/bin\n",
        "\n",
        "# Replace 'your-auth-token' with your actual ngrok authtoken\n",
        "!ngrok authtoken 'your auth token'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "mmHWLEsfaPyt",
        "outputId": "1237dc42-3780-4c96-ebf0-d91b642462a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * Running on http://4036-35-237-20-254.ngrok-free.app\n",
            " * Traffic stats available on http://127.0.0.1:4040\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [16/Dec/2023 17:17:59] \"GET / HTTP/1.1\" 200 -\n",
            "INFO:werkzeug:127.0.0.1 - - [16/Dec/2023 17:17:59] \"\u001b[33mGET /favicon.ico HTTP/1.1\u001b[0m\" 404 -\n",
            "INFO:werkzeug:127.0.0.1 - - [16/Dec/2023 17:18:17] \"POST / HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpg 생성됨\n",
            "csv 생성됨\n",
            "Processing file: 0-cpg.dot\n",
            "Processing file: 1-cpg.dot\n",
            "Processing file: 2-cpg.dot\n",
            "Processing file: 3-cpg.dot\n",
            "Processing file: 4-cpg.dot\n",
            "Processing file: 5-cpg.dot\n",
            "Processing file: 6-cpg.dot\n",
            "Convert \"CPG\"csv to graph\n",
            "Complete!\n",
            "모델 불러옴\n",
            "예측\n",
            "예측 수행함\n",
            "0번째 예측 : 1.218\n",
            "1번째 예측 : 1.291\n",
            "2번째 예측 : 1.301\n",
            "3번째 예측 : 1.301\n",
            "4번째 예측 : 1.288\n",
            "5번째 예측 : 1.31\n",
            "6번째 예측 : 1.301\n",
            "result 세팅함\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [16/Dec/2023 17:19:20] \"POST / HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpg 생성됨\n",
            "csv 생성됨\n",
            "Processing file: 0-cpg.dot\n",
            "Processing file: 1-cpg.dot\n",
            "Processing file: 2-cpg.dot\n",
            "Processing file: 3-cpg.dot\n",
            "Processing file: 4-cpg.dot\n",
            "Processing file: 5-cpg.dot\n",
            "Processing file: 6-cpg.dot\n",
            "Convert \"CPG\"csv to graph\n",
            "Complete!\n",
            "모델 불러옴\n",
            "예측\n",
            "예측 수행함\n",
            "0번째 예측 : 1.205\n",
            "1번째 예측 : 1.291\n",
            "2번째 예측 : 1.301\n",
            "3번째 예측 : 1.301\n",
            "4번째 예측 : 1.288\n",
            "5번째 예측 : 1.31\n",
            "6번째 예측 : 1.301\n",
            "result 세팅함\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [16/Dec/2023 17:20:44] \"POST / HTTP/1.1\" 200 -\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "cpg 생성됨\n",
            "csv 생성됨\n",
            "Processing file: 0-cpg.dot\n",
            "Processing file: 1-cpg.dot\n",
            "Processing file: 2-cpg.dot\n",
            "Processing file: 3-cpg.dot\n",
            "Convert \"CPG\"csv to graph\n",
            "Complete!\n",
            "모델 불러옴\n",
            "예측\n",
            "예측 수행함\n",
            "0번째 예측 : 1.234\n",
            "1번째 예측 : 1.25\n",
            "2번째 예측 : 1.266\n",
            "3번째 예측 : 1.259\n",
            "result 세팅함\n"
          ]
        }
      ],
      "source": [
        "from flask import Flask, render_template, request, jsonify\n",
        "from flask_ngrok import run_with_ngrok\n",
        "# app = Flask(__name__)\n",
        "app = Flask(__name__, template_folder='/content/drive/MyDrive/Colab Notebooks/Web/templates')\n",
        "run_with_ngrok(app)\n",
        "\n",
        "@app.route(\"/\", methods=['GET','POST'])\n",
        "def start():\n",
        "  result = None\n",
        "  input_data = ''\n",
        "  if request.method == 'POST':\n",
        "    # 사용자가 입력한 자바 소스코드\n",
        "    input_data = request.form['input_data']\n",
        "\n",
        "    # 입력한 소스코드로 java 파일 생성\n",
        "    f = open(\"/content/drive/MyDrive/jongsul/input.java\",\"w+\")\n",
        "    f.write(input_data)\n",
        "    f.close()\n",
        "\n",
        "    # cpg 생성\n",
        "    script_path = '/content/drive/MyDrive/jongsul/fixed.sh'\n",
        "    execute_script(script_path)\n",
        "\n",
        "    print(\"cpg 생성됨\")\n",
        "\n",
        "    # csv 생성\n",
        "    folder_path = \"/content/drive/MyDrive/jongsul/output\"\n",
        "    output_csv_path = \"/content/drive/MyDrive/jongsul/csv/toCsv.csv\"\n",
        "\n",
        "    print(\"csv 생성됨\")\n",
        "\n",
        "\n",
        "    # Create or clear the existing CSV file and write the header\n",
        "    write_to_csv_header(output_csv_path)\n",
        "\n",
        "    process_all_dot_files(folder_path, output_csv_path)\n",
        "\n",
        "\n",
        "    # 예측\n",
        "    # 예측에 사용할 데이터 불러오기\n",
        "    predict_dataset = CPGPredictDataset(csv_file='/content/drive/MyDrive/jongsul/csv/toCsv.csv')  # 예측에 사용할 데이터의 경로\n",
        "    predict_data_list = [predict_dataset[i] for i in range(len(predict_dataset.graph_list))]\n",
        "\n",
        "    # DataLoader 생성\n",
        "    predict_loader = DataLoader(predict_data_list, batch_size=64)\n",
        "\n",
        "    # 모델 불러오기\n",
        "    model = GCN(num_node_features=num_node_features)\n",
        "    model.load_state_dict(torch.load('/content/drive/MyDrive/jongsul/gcn_model.pth'))\n",
        "    model = model.to(device)\n",
        "    model.eval()\n",
        "\n",
        "    print(\"모델 불러옴\")\n",
        "\n",
        "\n",
        "    # 예측 수행\n",
        "    predictions = []\n",
        "    with torch.no_grad():\n",
        "        for predict_data in predict_loader:\n",
        "            print(\"예측\")\n",
        "            predict_data = predict_data.to(device)\n",
        "            output = model(predict_data)\n",
        "            predictions.extend(output.cpu().numpy())\n",
        "\n",
        "    print(\"예측 수행함\")\n",
        "\n",
        "    # 예측 결과 출력\n",
        "    sum = 0\n",
        "    count = 0\n",
        "    for i, prediction in enumerate(predictions):\n",
        "        print(str(i)+\"번째 예측 : \"+str(interpret_prediction(prediction)))\n",
        "        sum+=interpret_prediction(prediction)\n",
        "        count+=1\n",
        "        # print(f\"Time Complexity of input data is {interpret_prediction(prediction)}\")  # 예측 값을 해석하여 출력합니다.\n",
        "\n",
        "    resVal = sum/count\n",
        "\n",
        "    result = \"\"\n",
        "\n",
        "    if 0 <= resVal <= 0.5:\n",
        "      result = \"O(1)\"\n",
        "    elif 0.5 < resVal <= 1.5:\n",
        "      result = \"O(logn)\"\n",
        "    elif 1.5 < resVal <= 2.5:\n",
        "      result = \"O(n)\"\n",
        "    elif 2.5< resVal <= 3.5:\n",
        "      result = \"O(nlogn)\"\n",
        "    elif 3.5< resVal <= 4.5:\n",
        "      result = \"O(n^2)\"\n",
        "    else:\n",
        "      result = \"bigger\"\n",
        "\n",
        "    print(\"result 세팅함\")\n",
        "\n",
        "    # 결과\n",
        "    os.system('rm -rf /content/drive/MyDrive/jongsul/output')\n",
        "    os.system('rm -rf /content/drive/MyDrive/jongsul/csv/toCsv.csv')\n",
        "    os.system('rm -rf /content/drive/MyDrive/jongsul/input.java')\n",
        "\n",
        "\n",
        "  return render_template(\"index.html\", input_data=input_data, result=result)\n",
        "app.run()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCBVQHkOjjsU",
        "outputId": "d5448d38-bbfd-4240-fe50-0096f89d9628"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "os.system('rm -rf /content/drive/MyDrive/jongsul/output')\n",
        "os.system('rm -rf /content/drive/MyDrive/jongsul/csv/toCsv.csv')\n",
        "os.system('rm -rf /content/drive/MyDrive/jongsul/input.java')\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
