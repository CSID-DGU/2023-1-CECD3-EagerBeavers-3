{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "FUqq70rgTN90"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CSID-DGU/2023-1-CECD3-EagerBeavers-3/blob/main/auto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sP3a7H4AYk-",
        "outputId": "82eb6046-991f-464c-878b-70e6db821373"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import networkx as nx\n",
        "import pandas as pd\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCzQMNyPl0dd",
        "outputId": "701a0ec3-b1a3-4874-8043-7b828be90b71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# cpg 생성"
      ],
      "metadata": {
        "id": "wvOIZvlcTMG6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, sys\n",
        "\n",
        "# 권한 부여하기\n",
        "os.system('chmod +x /content/drive/MyDrive/jongsul/fixed.sh')\n",
        "# 실행하기\n",
        "os.system('sh /content/drive/MyDrive/jongsul/fixed.sh')"
      ],
      "metadata": {
        "id": "eIulJlNoTFvq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c14c226c-e20d-42d1-978e-fe20c9bc1459"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# csv 생성"
      ],
      "metadata": {
        "id": "FUqq70rgTN90"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "\n",
        "def main():\n",
        "    folder_path = \"/content/drive/MyDrive/jongsul/output\"\n",
        "    output_csv_path = \"/content/drive/MyDrive/jongsul/csv/toCsv.csv\"\n",
        "\n",
        "    # Create or clear the existing CSV file and write the header\n",
        "    write_to_csv_header(output_csv_path)\n",
        "\n",
        "    process_all_dot_files(folder_path, output_csv_path)\n",
        "\n",
        "def process_all_dot_files(folder_path, output_csv_path):\n",
        "    for file_name in os.listdir(folder_path):\n",
        "        if file_name.endswith(\".dot\"):\n",
        "            file_path = os.path.join(folder_path, file_name)\n",
        "            print(f\"Processing file: {file_name}\")\n",
        "            try:\n",
        "                nodes_and_edges = extract_node_and_edge_info(file_path)\n",
        "                write_to_csv(file_name, nodes_and_edges, output_csv_path)\n",
        "            except IOError as e:\n",
        "                print(f\"Error processing file {file_name}: {e}\")\n",
        "\n",
        "def extract_node_and_edge_info(file_path):\n",
        "    nodes = []\n",
        "    edges = []\n",
        "\n",
        "    with open(file_path, 'r') as file:\n",
        "        dot_content = file.read()\n",
        "\n",
        "        # Extract and print labels\n",
        "        node_pattern = re.compile(r'\"(\\d+)\"\\s*\\[label\\s*=\\s*<\\s*\\(([^,]+)')\n",
        "        node_matches = node_pattern.findall(dot_content)\n",
        "\n",
        "        for node_match in node_matches:\n",
        "            node_number, literal_value = node_match\n",
        "            node = f\"{node_number}:{literal_value}\"\n",
        "            nodes.append(node)\n",
        "\n",
        "        # Extract and print edge information\n",
        "        edge_pattern = re.compile(r'\"(\\S+)\"\\s*->\\s*\"(\\S+)\"\\s*\\[\\s*label\\s*=\\s*\"([^\"]+)\"\\s*\\]')\n",
        "        edge_matches = edge_pattern.findall(dot_content)\n",
        "\n",
        "        for edge_match in edge_matches:\n",
        "            source_node, target_node, label = edge_match\n",
        "            cleaned_label = label.rstrip(':').strip()\n",
        "            edge = f\"{source_node}->{target_node}:{cleaned_label}\"\n",
        "            edges.append(edge)\n",
        "\n",
        "    return '|'.join(nodes) + \"$\" + '|'.join(edges)\n",
        "\n",
        "def write_to_csv_header(output_csv_path):\n",
        "    with open(output_csv_path, 'w') as csv_file:\n",
        "        # Write CSV header\n",
        "        csv_file.write(\"index,nodes,edges,time\\n\")\n",
        "\n",
        "def write_to_csv(file_name, nodes_and_edges, output_csv_path):\n",
        "    cleaned_file_name = extract_numeric_part(file_name)\n",
        "\n",
        "    # Split nodes and edges using \"|\"\n",
        "    parts = nodes_and_edges.split(\"$\")\n",
        "\n",
        "    if len(parts) == 2:\n",
        "        # Write file name, nodes, and edges to CSV\n",
        "        with open(output_csv_path, 'a') as csv_file:\n",
        "            csv_file.write(f\"{cleaned_file_name},\\\"{parts[0]}\\\",\\\"{parts[1]}\\\"\\n\")\n",
        "    else:\n",
        "        # Handle the case when the format is unexpected\n",
        "        with open(output_csv_path, 'a') as csv_file:\n",
        "            csv_file.write(\"\\\"\\\",\\\"\\\",{nodes_and_edges}\\n\")\n",
        "\n",
        "def extract_numeric_part(file_name):\n",
        "    pattern = re.compile(r'\\d+')\n",
        "    match = pattern.search(file_name)\n",
        "\n",
        "    if match:\n",
        "        return match.group()\n",
        "\n",
        "    return \"\"\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "id": "NFkr-pNPTGAh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2f9ca3e2-0ad6-4f0b-b64a-730d4f9542cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing file: 0-cpg.dot\n",
            "Processing file: 1-cpg.dot\n",
            "Processing file: 2-cpg.dot\n",
            "Processing file: 3-cpg.dot\n",
            "Processing file: 4-cpg.dot\n",
            "Processing file: 5-cpg.dot\n",
            "Processing file: 6-cpg.dot\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터프레임 생성"
      ],
      "metadata": {
        "collapsed": false,
        "id": "o-8tE0P4R9ze"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 학습용 데이터 랜덤시드 설정"
      ],
      "metadata": {
        "collapsed": false,
        "id": "QiN_HUxlR9zg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric"
      ],
      "metadata": {
        "id": "tZOTEFb-6n6I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4a2b3bd-13fc-4b30-856c-36b2f775f6a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.4.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.11.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2023.11.17)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.2.0)\n",
            "Installing collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytorch-tabnet"
      ],
      "metadata": {
        "id": "RlqfkSa77kjY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "302c7fef-6e9e-4319-a08e-d22d30e09345"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytorch-tabnet\n",
            "  Downloading pytorch_tabnet-4.1.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.5/44.5 kB\u001b[0m \u001b[31m757.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.23.5)\n",
            "Requirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.2.2)\n",
            "Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (2.1.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (4.66.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3->pytorch-tabnet) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3->pytorch-tabnet) (1.3.0)\n",
            "Installing collected packages: pytorch-tabnet\n",
            "Successfully installed pytorch-tabnet-4.1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 데이터셋 정의\n",
        "### 훈련 및 테스트 데이터 분류\n",
        "###"
      ],
      "metadata": {
        "id": "Bb0OsMdZ-5sK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "collapsed": false,
        "id": "xeUl5AZb-j61"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.data import Data\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n"
      ],
      "metadata": {
        "id": "0mHMISf4Ctpm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 입력 데이터에 대한 클래스 정의"
      ],
      "metadata": {
        "collapsed": false,
        "id": "5XhXj84PR9zm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "class CPGPredictDataset(Dataset):\n",
        "    def __init__(self, csv_file):\n",
        "        super(CPGPredictDataset, self).__init__()\n",
        "\n",
        "        self.df = pd.read_csv(csv_file)\n",
        "        self.df.fillna(0, inplace=True)\n",
        "\n",
        "        self.wo_cpgs_df = self.df.drop(columns=['index', 'nodes', 'edges'])\n",
        "        self.wo_cpgs_df = torch.tensor(self.wo_cpgs_df.values.astype(np.float32))\n",
        "\n",
        "        self.graph_list = self.cpgs2graph(self.df['nodes'], self.df['edges'])\n",
        "\n",
        "        self.label_encoder = LabelEncoder()\n",
        "\n",
        "        all_features = []\n",
        "        for idx in range(len(self.graph_list)):\n",
        "            graph_data = self.graph_list[idx]\n",
        "            features = [data['feature'] for _, data in graph_data.nodes(data=True)]\n",
        "            all_features.extend(features)\n",
        "\n",
        "        self.label_encoder.fit(all_features)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.graph_list)\n",
        "\n",
        "    def cpgs2graph_single(self, nodes, edges):\n",
        "        # 노드 및 엣지 정보 추출\n",
        "        nodes_info = [node.split(':') for node in nodes.split('|') if node]\n",
        "\n",
        "        if isinstance(edges, str):\n",
        "            edges_info = [edge.split('->') for edge in edges.split('|') if edge]\n",
        "        elif isinstance(edges, int):\n",
        "            edges_info = []\n",
        "        else:\n",
        "            raise ValueError(\"Invalid type for 'edges'. Should be either str or int.\")\n",
        "\n",
        "        # 그래프 생성\n",
        "        G = nx.Graph()\n",
        "\n",
        "        # 노드 추가\n",
        "        for node_info in nodes_info:\n",
        "            if len(node_info) > 1:  # 노드 정보가 제대로 있다면\n",
        "                G.add_node(node_info[0], feature=node_info[1])\n",
        "\n",
        "        # 엣지 추가\n",
        "        for edge_info in edges_info:\n",
        "            # 엣지 특성을 추가\n",
        "            if len(edge_info) > 1:\n",
        "                source, target_feature = edge_info[0], edge_info[1].split(':')\n",
        "                if len(target_feature) > 1:\n",
        "                    target, feature = target_feature[0], target_feature[1]\n",
        "                    G.add_edge(source, target, feature=feature)\n",
        "                else:\n",
        "                    print(\"Error: Edge feature is missing.\")\n",
        "            else:\n",
        "                print(\"Error: Incomplete edge information.\")\n",
        "\n",
        "        return G\n",
        "\n",
        "\n",
        "    def cpgs2graph(self, nodes_list, edges_list):\n",
        "        print('Convert \"CPG\"csv to graph')\n",
        "\n",
        "        graph_list = []\n",
        "        for nodes, edges in zip(nodes_list, edges_list):\n",
        "            try:\n",
        "                # 노드와 엣지를 그래프로 변환\n",
        "                G = self.cpgs2graph_single(nodes, edges)\n",
        "                graph_list.append(G)\n",
        "            except Exception as e:\n",
        "                print(f\"Error creating graph: {e}\")\n",
        "\n",
        "        print('Complete!')\n",
        "        return graph_list\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        graph_data = self.graph_list[idx]\n",
        "\n",
        "        nodes_info = [(node, self.label_encoder.transform([data['feature']])[0]) for node, data in graph_data.nodes(data=True)]\n",
        "        edges_info = [(u, v, data['feature']) for u, v, data in graph_data.edges(data=True)]\n",
        "\n",
        "        node_indices = [node[0] for node in nodes_info]\n",
        "        edges = [(node_indices.index(u), node_indices.index(v)) for u, v, _ in edges_info]\n",
        "\n",
        "        # edge_index 텐서 생성\n",
        "        edge_index = torch.tensor(list(zip(*edges)), dtype=torch.long)\n",
        "\n",
        "        # node feature 텐서 생성\n",
        "        x = torch.tensor([node[1] for node in nodes_info], dtype=torch.float).view(-1, 1)\n",
        "\n",
        "        data = Data(x=x, edge_index=edge_index)\n",
        "\n",
        "        return data\n"
      ],
      "metadata": {
        "id": "rOPQQTs9R9zm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 모델 생성 및 학습\n"
      ],
      "metadata": {
        "id": "oSNZ9Wha-vrs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Y08Sn9cYirY",
        "outputId": "caf09721-e2a7-4725-b702-f60fe92409c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JEQ1E8h1ZFcc",
        "outputId": "8ba2dc7c-e0dd-48bb-b4d0-a296c0312dc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: You must give at least one requirement to install (see \"pip help install\")\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install torch_geometric\n",
        "!pip install pytorch-tabnet\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nGfSDiDVZPll",
        "outputId": "a0d9b808-d12f-4561-c744-7f088a0cc07e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.11.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2023.11.17)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.2.0)\n",
            "Requirement already satisfied: pytorch-tabnet in /usr/local/lib/python3.10/dist-packages (4.1.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.23.5)\n",
            "Requirement already satisfied: scikit_learn>0.21 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.2.2)\n",
            "Requirement already satisfied: scipy>1.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (1.11.4)\n",
            "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (2.1.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.10/dist-packages (from pytorch-tabnet) (4.66.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn>0.21->pytorch-tabnet) (3.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.3->pytorch-tabnet) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.3->pytorch-tabnet) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.3->pytorch-tabnet) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import global_mean_pool\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n"
      ],
      "metadata": {
        "id": "xPcDnsAL-j64"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.data import Data\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "class CPGPredictDataset(Dataset):\n",
        "    def __init__(self, csv_file):\n",
        "        super(CPGPredictDataset, self).__init__()\n",
        "\n",
        "        self.df = pd.read_csv(csv_file)\n",
        "        self.df.fillna(0, inplace=True)\n",
        "\n",
        "        self.wo_cpgs_df = self.df.drop(columns=['index', 'nodes', 'edges', 'time'])\n",
        "        self.wo_cpgs_df = torch.tensor(self.wo_cpgs_df.values.astype(np.float32))\n",
        "\n",
        "        self.graph_list = self.cpgs2graph(self.df['nodes'], self.df['edges'])\n",
        "\n",
        "        self.label_encoder = LabelEncoder()\n",
        "\n",
        "        all_features = []\n",
        "        for idx in range(len(self.graph_list)):\n",
        "            graph_data = self.graph_list[idx]\n",
        "            features = [data['feature'] for _, data in graph_data.nodes(data=True)]\n",
        "            all_features.extend(features)\n",
        "\n",
        "        self.label_encoder.fit(all_features)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.graph_list)\n",
        "\n",
        "    def cpgs2graph_single(self, nodes, edges):\n",
        "        # 노드 및 엣지 정보 추출\n",
        "        nodes_info = [node.split(':') for node in nodes.split('|') if node]\n",
        "\n",
        "        if isinstance(edges, str):\n",
        "            edges_info = [edge.split('->') for edge in edges.split('|') if edge]\n",
        "        elif isinstance(edges, int):\n",
        "            edges_info = []\n",
        "        else:\n",
        "            raise ValueError(\"Invalid type for 'edges'. Should be either str or int.\")\n",
        "\n",
        "        # 그래프 생성\n",
        "        G = nx.Graph()\n",
        "\n",
        "        # 노드 추가\n",
        "        for node_info in nodes_info:\n",
        "            if len(node_info) > 1:  # 노드 정보가 제대로 있다면\n",
        "                G.add_node(node_info[0], feature=node_info[1])\n",
        "\n",
        "        # 엣지 추가\n",
        "        for edge_info in edges_info:\n",
        "            # 엣지 특성을 추가\n",
        "            if len(edge_info) > 1:\n",
        "                source, target_feature = edge_info[0], edge_info[1].split(':')\n",
        "                if len(target_feature) > 1:\n",
        "                    target, feature = target_feature[0], target_feature[1]\n",
        "                    G.add_edge(source, target, feature=feature)\n",
        "                else:\n",
        "                    print(\"Error: Edge feature is missing.\")\n",
        "            else:\n",
        "                print(\"Error: Incomplete edge information.\")\n",
        "\n",
        "        return G\n",
        "\n",
        "\n",
        "    def cpgs2graph(self, nodes_list, edges_list):\n",
        "        print('Convert \"CPG\"csv to graph')\n",
        "\n",
        "        graph_list = []\n",
        "        for nodes, edges in zip(nodes_list, edges_list):\n",
        "            try:\n",
        "                # 노드와 엣지를 그래프로 변환\n",
        "                G = self.cpgs2graph_single(nodes, edges)\n",
        "                graph_list.append(G)\n",
        "            except Exception as e:\n",
        "                print(f\"Error creating graph: {e}\")\n",
        "\n",
        "        print('Complete!')\n",
        "        return graph_list\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        graph_data = self.graph_list[idx]\n",
        "\n",
        "        nodes_info = [(node, self.label_encoder.transform([data['feature']])[0]) for node, data in graph_data.nodes(data=True)]\n",
        "        edges_info = [(u, v, data['feature']) for u, v, data in graph_data.edges(data=True)]\n",
        "\n",
        "        node_indices = [node[0] for node in nodes_info]\n",
        "        edges = [(node_indices.index(u), node_indices.index(v)) for u, v, _ in edges_info]\n",
        "\n",
        "        # edge_index 텐서 생성\n",
        "        edge_index = torch.tensor(list(zip(*edges)), dtype=torch.long)\n",
        "\n",
        "        # node feature 텐서 생성\n",
        "        x = torch.tensor([node[1] for node in nodes_info], dtype=torch.float).view(-1, 1)\n",
        "\n",
        "        data = Data(x=x, edge_index=edge_index)\n",
        "\n",
        "        return data"
      ],
      "metadata": {
        "id": "cMgs5-xaZrqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 입력 데이터에 대한 예측 수행"
      ],
      "metadata": {
        "collapsed": false,
        "id": "7vLi0ZrJR9zn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Convert \"CPG\"csv to graph\n",
            "Complete!\n",
            "Time Complexity of input data is logn in Big-O Notation, predicted value was : 1.2300000190734863\n",
            "Time Complexity of input data is logn in Big-O Notation, predicted value was : 1.2910000085830688\n",
            "Time Complexity of input data is logn in Big-O Notation, predicted value was : 1.3009999990463257\n",
            "Time Complexity of input data is logn in Big-O Notation, predicted value was : 1.3009999990463257\n",
            "Time Complexity of input data is logn in Big-O Notation, predicted value was : 1.2879999876022339\n",
            "Time Complexity of input data is logn in Big-O Notation, predicted value was : 1.309999942779541\n",
            "Time Complexity of input data is logn in Big-O Notation, predicted value was : 1.3009999990463257\n"
          ]
        }
      ],
      "source": [
        "num_node_features = 1  # 노드 피처의 차원\n",
        "\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, num_node_features):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GCNConv(num_node_features, 16)\n",
        "        self.conv2 = GCNConv(16, 1)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, training=self.training)\n",
        "\n",
        "        x = self.conv2(x, edge_index)\n",
        "\n",
        "        x = global_mean_pool(x, data.batch)\n",
        "\n",
        "        return x.view(-1)\n",
        "\n",
        "#예측 결과 출력 함수\n",
        "def interpret_prediction(prediction):\n",
        "    # numpy.round를 사용하여 소수점 3자리에서 반올림\n",
        "    rounded_pred = np.round(prediction, 3)\n",
        "\n",
        "    # 소수점 이하 3자리까지만 출력하도록 문자열 형식으로 변환\n",
        "    rounded_pred_str = f\"{rounded_pred:.3f}\"\n",
        "    # 범위에 따른 문자열 반환\n",
        "    if 0 <= rounded_pred <= 0.5:\n",
        "        return f\"constant in Big-O Notation, predicted value was : {rounded_pred}\"\n",
        "    elif 0.6 <= rounded_pred <= 1.5:\n",
        "        return f\"logn in Big-O Notation, predicted value was : {rounded_pred}\"\n",
        "    elif 1.6 <= rounded_pred <= 2.5:\n",
        "        return f\"linear in Big-O Notation, predicted value was : {rounded_pred}\"\n",
        "    elif 2.6 <= rounded_pred <= 3.5:\n",
        "        return f\"nlogn in Big-O Notation, predicted value was : {rounded_pred}\"\n",
        "    elif 3.6 <= rounded_pred <= 4.5:\n",
        "        return f\"quadratic in Big-O Notation, predicted value was : {rounded_pred}\"\n",
        "    else:\n",
        "        return f\"bigger than quadratic in Big-O Notation, predicted value was : {rounded_pred}\"\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "\n",
        "# 예측에 사용할 데이터 불러오기\n",
        "predict_dataset = CPGPredictDataset(csv_file='/content/drive/MyDrive/jongsul/csv/toCsv.csv')  # 예측에 사용할 데이터의 경로\n",
        "predict_data_list = [predict_dataset[i] for i in range(len(predict_dataset.graph_list))]\n",
        "\n",
        "# DataLoader 생성\n",
        "predict_loader = DataLoader(predict_data_list, batch_size=64)\n",
        "\n",
        "# 모델 불러오기\n",
        "model = GCN(num_node_features=num_node_features)\n",
        "model.load_state_dict(torch.load('/content/drive/MyDrive/jongsul/gcn_model.pth'))\n",
        "model = model.to(device)\n",
        "model.eval()\n",
        "\n",
        "# 예측 수행\n",
        "predictions = []\n",
        "with torch.no_grad():\n",
        "    for predict_data in predict_loader:\n",
        "        predict_data = predict_data.to(device)\n",
        "        output = model(predict_data)\n",
        "        predictions.extend(output.cpu().numpy())\n",
        "\n",
        "# 예측 결과 출력\n",
        "for i, prediction in enumerate(predictions):\n",
        "    print(f\"Time Complexity of input data is {interpret_prediction(prediction)}\")  # 예측 값을 해석하여 출력합니다.\n"
      ],
      "metadata": {
        "id": "L-VeSA0UR9zn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3d25439-59f5-4a5d-f569-77adf6103f10"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.system('rm -rf /content/drive/MyDrive/jongsul/output')\n",
        "os.system('rm -rf /content/drive/MyDrive/jongsul/csv/toCsv.csv')\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "8wlosJAOUnrx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b74733f-6cf0-406e-c958-ca9d070de599"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    }
  ]
}
