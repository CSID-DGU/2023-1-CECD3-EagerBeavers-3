{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5sP3a7H4AYk-",
        "outputId": "7ad5964c-2d09-4d3f-ebec-8fdfa7375b6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "import networkx as nx\n",
        "import pandas as pd\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = '/content/drive/MyDrive/labelling_file.csv'\n",
        "df = pd.read_csv(file_path)"
      ],
      "metadata": {
        "id": "1BRpxvIJSMJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "rd_seed = 42\n",
        "\n",
        "torch.manual_seed(rd_seed)\n",
        "np.random.seed(rd_seed)\n",
        "random.seed(rd_seed)\n",
        "\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False"
      ],
      "metadata": {
        "id": "hHUvwLiA0ews"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "train_df = pd.read_csv('/content/drive/MyDrive/labelling_file.csv')\n",
        "\n",
        "train_df.head()"
      ],
      "metadata": {
        "id": "I0eL_fhg5R2d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGvoOwtP6G5u",
        "outputId": "7fa0a241-6509-4d55-960a-6dadb6d2388b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1263 entries, 0 to 1262\n",
            "Data columns (total 4 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   index   1263 non-null   object \n",
            " 1   nodes   1263 non-null   object \n",
            " 2   edges   1261 non-null   object \n",
            " 3   time    1259 non-null   float64\n",
            "dtypes: float64(1), object(3)\n",
            "memory usage: 39.6+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch_geometric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tZOTEFb-6n6I",
        "outputId": "3d112ac4-7ae0-4e00-8778-3b86ea89391e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.4.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.11.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.31.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2023.7.22)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.2.0)\n",
            "Installing collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.nn import global_mean_pool\n",
        "\n",
        "class GraphFeature(nn.Module):\n",
        "    def __init__(self, node_feat, embed_dim):\n",
        "        super(GraphFeature, self).__init__()\n",
        "\n",
        "        self.conv_l1 = GCNConv(node_feat, 8)\n",
        "        self.conv_l2 = GCNConv(8, 16)\n",
        "        self.embedding = nn.Linear(16, embed_dim)\n",
        "\n",
        "    def forward(self, x, edge_idx, batch):\n",
        "        x = F.elu(self.conv_l1(x, edge_idx))\n",
        "        x = F.elu(self.conv_l2(x, edge_idx))\n",
        "\n",
        "        x = global_mean_pool(x, batch) # read-out layer\n",
        "\n",
        "        x = self.embedding(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "MtBBzVWu6qUg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.data import Data\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class CPGDataset(Dataset):\n",
        "    def __init__(self, csv_file, train_ratio=0.8):\n",
        "        super(CPGDataset, self).__init__()\n",
        "\n",
        "        self.df = pd.read_csv(csv_file)\n",
        "        self.df.fillna(0, inplace=True)\n",
        "        self.train_ratio = train_ratio\n",
        "        self._split_data()\n",
        "\n",
        "        self.target_result = torch.tensor(self.df['time'].values.astype(np.float32))\n",
        "        self.wo_cpgs_df = self.df.drop(columns=['index', 'nodes', 'edges', 'time'])\n",
        "        self.wo_cpgs_df = torch.tensor(self.wo_cpgs_df.values.astype(np.float32))\n",
        "\n",
        "        self.train_graph_list = self.cpgs2graph(self.train_df['nodes'], self.train_df['edges'], self.train_df['time'])\n",
        "        self.val_graph_list = self.cpgs2graph(self.val_df['nodes'], self.val_df['edges'], self.val_df['time'])\n",
        "        self.graph_list = self.cpgs2graph(self.df['nodes'], self.df['edges'], self.df['time'])\n",
        "\n",
        "        self.label_encoder = LabelEncoder()\n",
        "\n",
        "        all_features = []\n",
        "        for idx in range(len(self.graph_list)):\n",
        "            graph_data, time = self.graph_list[idx]\n",
        "            features = [data['feature'] for _, data in graph_data.nodes(data=True)]\n",
        "            all_features.extend(features)\n",
        "\n",
        "        self.label_encoder.fit(all_features)\n",
        "\n",
        "    def _split_data(self):\n",
        "        # 'time'을 기준으로 정렬\n",
        "        self.df = self.df.sort_values(by='time')\n",
        "\n",
        "        # 데이터셋을 train_ratio에 따라 나누기\n",
        "        split_idx = int(len(self.df) * self.train_ratio)\n",
        "        self.train_df = self.df.iloc[:split_idx]\n",
        "        self.val_df = self.df.iloc[split_idx:]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.train_graph_list)\n",
        "\n",
        "    def cpgs2graph_single(self, nodes, edges, time):\n",
        "        # 노드 및 엣지 정보 추출\n",
        "        nodes_info = [node.split(':') for node in nodes.split('|') if node]\n",
        "\n",
        "        if isinstance(edges, str):\n",
        "            edges_info = [edge.split('->') for edge in edges.split('|') if edge]\n",
        "        elif isinstance(edges, int):\n",
        "            edges_info = []\n",
        "        else:\n",
        "            raise ValueError(\"Invalid type for 'edges'. Should be either str or int.\")\n",
        "\n",
        "        # 그래프 생성\n",
        "        G = nx.Graph()\n",
        "\n",
        "        # 노드 추가\n",
        "        for node_info in nodes_info:\n",
        "            if len(node_info) > 1:  # 노드 정보가 제대로 있다면\n",
        "                G.add_node(node_info[0], feature=node_info[1])\n",
        "\n",
        "        # 엣지 추가\n",
        "        for edge_info in edges_info:\n",
        "            # 엣지 특성을 추가\n",
        "            if len(edge_info) > 1:\n",
        "                source, target_feature = edge_info[0], edge_info[1].split(':')\n",
        "                if len(target_feature) > 1:\n",
        "                    target, feature = target_feature[0], target_feature[1]\n",
        "                    G.add_edge(source, target, feature=feature)\n",
        "                else:\n",
        "                    print(\"Error: Edge feature is missing.\")\n",
        "            else:\n",
        "                print(\"Error: Incomplete edge information.\")\n",
        "\n",
        "        # 그래프에 'time' 라벨 추가\n",
        "        G.graph['time'] = time\n",
        "\n",
        "        return G\n",
        "\n",
        "    def cpgs2graph(self, nodes_list, edges_list, time_list):\n",
        "        print('Convert \"CPG\"csv to graph')\n",
        "\n",
        "        graph_list = []\n",
        "        for nodes, edges, time in zip(nodes_list, edges_list, time_list):\n",
        "            try:\n",
        "                # 노드와 엣지를 그래프로 변환\n",
        "                G = self.cpgs2graph_single(nodes, edges, time)\n",
        "                graph_list.append((G, time))\n",
        "            except Exception as e:\n",
        "                print(f\"Error creating graph: {e}\")\n",
        "\n",
        "        print('Complete!')\n",
        "        return graph_list\n",
        "\n",
        "\n",
        "    def visualize_graph(self, G, time):\n",
        "        pos = nx.spring_layout(G)  # 레이아웃 결정\n",
        "\n",
        "        # 노드 및 엣지 시각화\n",
        "        nx.draw_networkx_nodes(G, pos, node_size=700)\n",
        "        nx.draw_networkx_edges(G, pos)\n",
        "        nx.draw_networkx_labels(G, pos)\n",
        "\n",
        "        # 엣지에 대한 특성 시각화\n",
        "        edge_labels = nx.get_edge_attributes(G, 'feature')\n",
        "        nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels)\n",
        "\n",
        "        # 수정된 부분: 그래프에 'time' 라벨 출력\n",
        "        print(f\"Graph with time: {G.graph['time']}\")\n",
        "        plt.title(f\"Graph with time: {G.graph['time']}\")\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        graph_data, time = self.graph_list[idx]\n",
        "        y = self.target_result[idx]\n",
        "\n",
        "        nodes_info = [(node, self.label_encoder.transform([data['feature']])[0]) for node, data in graph_data.nodes(data=True)]\n",
        "        edges_info = [(u, v, data['feature']) for u, v, data in graph_data.edges(data=True)]\n",
        "\n",
        "        node_indices = [node[0] for node in nodes_info]\n",
        "        edges = [(node_indices.index(u), node_indices.index(v)) for u, v, _ in edges_info]\n",
        "\n",
        "        # edge_index 텐서 생성\n",
        "        edge_index = torch.tensor(list(zip(*edges)), dtype=torch.long)\n",
        "\n",
        "        # node feature 텐서 생성\n",
        "        x = torch.tensor([node[1] for node in nodes_info], dtype=torch.float).view(-1, 1)\n",
        "\n",
        "        # 타겟 텐서 생성\n",
        "        y = y.clone().detach()\n",
        "\n",
        "\n",
        "        data = Data(x=x, edge_index=edge_index, y=y)\n",
        "\n",
        "        return data\n"
      ],
      "metadata": {
        "id": "0mHMISf4Ctpm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = CPGDataset(csv_file='/content/drive/MyDrive/labelling_file.csv')\n",
        "\n",
        "print(\"Output shape:\", output.shape)\n",
        "print(\"Target shape:\", data.y.view(-1).long().shape)\n",
        "\n",
        "# DataLoader 생성\n",
        "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# DataLoader에서 첫 번째 배치 가져오기\n",
        "batch = next(iter(train_loader))\n",
        "\n",
        "# 첫 번째 배치의 데이터 출력\n",
        "print(batch)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FvWQAW3ymwfc",
        "outputId": "2b9718dc-c971-4fed-9f30-77af95450e42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Convert \"CPG\"csv to graph\n",
            "Error: Edge feature is missing.\n",
            "Error: Incomplete edge information.\n",
            "Complete!\n",
            "Convert \"CPG\"csv to graph\n",
            "Complete!\n",
            "Convert \"CPG\"csv to graph\n",
            "Error: Edge feature is missing.\n",
            "Error: Incomplete edge information.\n",
            "Complete!\n",
            "Output shape: torch.Size([5549, 5])\n",
            "Target shape: torch.Size([64])\n",
            "DataBatch(x=[7117, 1], edge_index=[2, 14625], y=[64], batch=[7117], ptr=[65])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트 그래프 시각화\n",
        "\n",
        "dataset = CPGDataset('/content/drive/MyDrive/labelling_file.csv', train_ratio=0.8)\n",
        "\n",
        "print()\n",
        "print(len(dataset))\n",
        "\n",
        "for i, (graph, time) in enumerate(dataset.graph_list):\n",
        "    print(f\"Visualizing Graph {i + 1}\")\n",
        "    dataset.visualize_graph(graph, time)\n"
      ],
      "metadata": {
        "id": "jJHoEEsVFDa1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.loader import DataLoader\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, num_node_features, num_classes):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GCNConv(num_node_features, 16)\n",
        "        self.conv2 = GCNConv(16, num_classes)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "\n",
        "        # 첫 번째 GCN 레이어\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, training=self.training)\n",
        "\n",
        "        # 두 번째 GCN 레이어\n",
        "        x = self.conv2(x, edge_index)\n",
        "\n",
        "        # 최종 노드 임베딩\n",
        "        return F.log_softmax(x, dim=1)\n",
        "\n",
        "# 데이터셋 및 모델 초기화\n",
        "dataset = CPGDataset(csv_file='/content/drive/MyDrive/labelling_file.csv')\n",
        "num_node_features = dataset.wo_cpgs_df.size(1)  # 노드 피처의 차원\n",
        "num_classes = 5\n",
        "model = GCN(num_node_features=num_node_features, num_classes=num_classes).to(device)\n",
        "\n",
        "# 훈련 및 검증 데이터로더 설정\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# 손실 함수 및 옵티마이저 설정\n",
        "criterion = torch.nn.NLLLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
        "\n",
        "\n",
        "# 학습 루프\n",
        "epochs = 10\n",
        "model.train()\n",
        "for epoch in range(epochs):\n",
        "    for data in train_loader:\n",
        "        data = data.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, data.y.long())\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "# 검증 데이터를 사용하여 성능 평가\n",
        "model.eval()\n",
        "val_correct = 0\n",
        "val_total = 0\n",
        "with torch.no_grad():\n",
        "    for val_data in val_loader:\n",
        "        val_data = val_data.to(device)\n",
        "        val_output = model(val_data)\n",
        "        _, val_predicted = torch.max(val_output, 1)\n",
        "        val_total += val_data.target_result.size(0)\n",
        "        val_correct += (val_predicted == val_data.target_result.view(-1).long()).sum().item()\n",
        "\n",
        "val_accuracy = 100 * val_correct / val_total\n",
        "print(f'Epoch {epoch + 1}/{epochs}, Validation Accuracy: {val_accuracy:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "nTjDizKIGGn7",
        "outputId": "066b655f-dec3-43c6-9648-640d727ac7d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-349e1698bfab>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGCNConv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch_geometric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch_geometric'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    }
  ]
}