{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5sP3a7H4AYk-",
    "outputId": "fb4e6fa5-3a0b-461d-af90-f64f7f39861e"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "file_path = '/content/drive/MyDrive/labelling_file.csv'\n",
    "df = pd.read_csv(file_path)"
   ],
   "metadata": {
    "id": "1BRpxvIJSMJY"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "result_counts = df['result'].value_counts()\n",
    "print(\"Result Counts:\")\n",
    "print(result_counts)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-uSSCSc1SSln",
    "outputId": "1193adcf-14f8-4dd0-ca76-d64482825a14"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Result Counts:\n",
      "0    380\n",
      "2    307\n",
      "3    258\n",
      "4    169\n",
      "1    147\n",
      "Name: result, dtype: int64\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "#무작위 시드 설정\n",
    "rd_seed = 42\n",
    "\n",
    "torch.manual_seed(rd_seed)\n",
    "np.random.seed(rd_seed)\n",
    "random.seed(rd_seed)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ],
   "metadata": {
    "id": "hHUvwLiA0ews"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "train_df = pd.read_csv('/content/drive/MyDrive/labelling_file.csv')\n",
    "\n",
    "train_df.head()"
   ],
   "metadata": {
    "id": "I0eL_fhg5R2d"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_df.info()"
   ],
   "metadata": {
    "id": "EGvoOwtP6G5u"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install torch_geometric"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tZOTEFb-6n6I",
    "outputId": "22592f2c-625d-4aa9-bb39-57018d8b381e"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: torch_geometric in /usr/local/lib/python3.10/dist-packages (2.4.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.1)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.23.5)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.11.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.31.0)\n",
      "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.1)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n",
      "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2023.7.22)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.2.0)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install pytorch-tabnet"
   ],
   "metadata": {
    "id": "RlqfkSa77kjY"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 데이터셋 정의\n",
    "### 훈련 및 테스트 데이터 분류\n",
    "###"
   ],
   "metadata": {
    "id": "Bb0OsMdZ-5sK"
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "id": "xeUl5AZb-j61"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Data\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class CPGDataset(Dataset):\n",
    "    def __init__(self, csv_file, train_ratio=0.8, k_fold=10):\n",
    "        super(CPGDataset, self).__init__()\n",
    "\n",
    "        self.df = pd.read_csv(csv_file)\n",
    "        self.df.fillna(0, inplace=True)\n",
    "        self.train_ratio = train_ratio\n",
    "        self.k_fold = k_fold\n",
    "        self._split_data()\n",
    "\n",
    "        self.target_result = torch.tensor(self.df['time'].values.astype(np.float32))\n",
    "        self.wo_cpgs_df = self.df.drop(columns=['index', 'nodes', 'edges', 'time'])\n",
    "        self.wo_cpgs_df = torch.tensor(self.wo_cpgs_df.values.astype(np.float32))\n",
    "\n",
    "        self.train_graph_list = self.cpgs2graph(self.train_df['nodes'], self.train_df['edges'], self.train_df['time'])\n",
    "        self.val_graph_list = self.cpgs2graph(self.val_df['nodes'], self.val_df['edges'], self.val_df['time'])\n",
    "        self.graph_list = self.cpgs2graph(self.df['nodes'], self.df['edges'], self.df['time'])\n",
    "\n",
    "        self.label_encoder = LabelEncoder()\n",
    "\n",
    "        all_features = []\n",
    "        for idx in range(len(self.graph_list)):\n",
    "            graph_data, time = self.graph_list[idx]\n",
    "            features = [data['feature'] for _, data in graph_data.nodes(data=True)]\n",
    "            all_features.extend(features)\n",
    "\n",
    "        self.label_encoder.fit(all_features)\n",
    "\n",
    "        # 데이터 분할\n",
    "    def _split_data(self):\n",
    "        # 'time'을 기준으로 정렬\n",
    "        self.df = self.df.sort_values(by='time')\n",
    "\n",
    "        # 데이터셋을 train_ratio에 따라 나누기\n",
    "        kf = KFold(n_splits=self.k_fold, shuffle=True, random_state=42)\n",
    "\n",
    "        for train_index, val_index in kf.split(self.df):\n",
    "            self.train_df = self.df.iloc[train_index]\n",
    "            self.val_df = self.df.iloc[val_index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.train_graph_list)\n",
    "\n",
    "    def cpgs2graph_single(self, nodes, edges, time):\n",
    "        # 노드 및 엣지 정보 추출\n",
    "        nodes_info = [node.split(':') for node in nodes.split('|') if node]\n",
    "\n",
    "        if isinstance(edges, str):\n",
    "            edges_info = [edge.split('->') for edge in edges.split('|') if edge]\n",
    "        elif isinstance(edges, int):\n",
    "            edges_info = []\n",
    "        else:\n",
    "            raise ValueError(\"Invalid type for 'edges'. Should be either str or int.\")\n",
    "\n",
    "        # 그래프 생성\n",
    "        G = nx.Graph()\n",
    "\n",
    "        # 노드 추가\n",
    "        for node_info in nodes_info:\n",
    "            if len(node_info) > 1:  # 노드 정보가 제대로 있다면\n",
    "                G.add_node(node_info[0], feature=node_info[1])\n",
    "\n",
    "        # 엣지 추가\n",
    "        for edge_info in edges_info:\n",
    "            # 엣지 특성을 추가\n",
    "            if len(edge_info) > 1:\n",
    "                source, target_feature = edge_info[0], edge_info[1].split(':')\n",
    "                if len(target_feature) > 1:\n",
    "                    target, feature = target_feature[0], target_feature[1]\n",
    "                    G.add_edge(source, target, feature=feature)\n",
    "                else:\n",
    "                    print(\"Error: Edge feature is missing.\")\n",
    "            else:\n",
    "                print(\"Error: Incomplete edge information.\")\n",
    "\n",
    "        # 그래프에 'time' 라벨 추가\n",
    "        G.graph['time'] = time\n",
    "\n",
    "        return G\n",
    "\n",
    "    def cpgs2graph(self, nodes_list, edges_list, time_list):\n",
    "        print('Convert \"CPG\"csv to graph')\n",
    "\n",
    "        graph_list = []\n",
    "        for nodes, edges, time in zip(nodes_list, edges_list, time_list):\n",
    "            try:\n",
    "                # 노드와 엣지를 그래프로 변환\n",
    "                G = self.cpgs2graph_single(nodes, edges, time)\n",
    "                graph_list.append((G, time))\n",
    "            except Exception as e:\n",
    "                print(f\"Error creating graph: {e}\")\n",
    "\n",
    "        print('Complete!')\n",
    "        return graph_list\n",
    "\n",
    "\n",
    "    def visualize_graph(self, G, time):\n",
    "        pos = nx.spring_layout(G)  # 레이아웃 결정\n",
    "\n",
    "        # 노드 및 엣지 시각화\n",
    "        nx.draw_networkx_nodes(G, pos, node_size=700)\n",
    "        nx.draw_networkx_edges(G, pos)\n",
    "        nx.draw_networkx_labels(G, pos)\n",
    "\n",
    "        # 엣지에 대한 특성 시각화\n",
    "        edge_labels = nx.get_edge_attributes(G, 'feature')\n",
    "        nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_labels)\n",
    "\n",
    "        # 수정된 부분: 그래프에 'time' 라벨 출력\n",
    "        print(f\"Graph with time: {G.graph['time']}\")\n",
    "        plt.title(f\"Graph with time: {G.graph['time']}\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        graph_data, time = self.graph_list[idx]\n",
    "        y = self.target_result[idx]\n",
    "\n",
    "        nodes_info = [(node, self.label_encoder.transform([data['feature']])[0]) for node, data in graph_data.nodes(data=True)]\n",
    "        edges_info = [(u, v, data['feature']) for u, v, data in graph_data.edges(data=True)]\n",
    "\n",
    "        node_indices = [node[0] for node in nodes_info]\n",
    "        edges = [(node_indices.index(u), node_indices.index(v)) for u, v, _ in edges_info]\n",
    "\n",
    "        # edge_index 텐서 생성\n",
    "        edge_index = torch.tensor(list(zip(*edges)), dtype=torch.long)\n",
    "\n",
    "        # node feature 텐서 생성\n",
    "        x = torch.tensor([node[1] for node in nodes_info], dtype=torch.float).view(-1, 1)\n",
    "\n",
    "        # 타겟 텐서 생성\n",
    "        y = y.clone().detach()\n",
    "\n",
    "\n",
    "        data = Data(x=x, edge_index=edge_index, y=y)\n",
    "\n",
    "        return data\n"
   ],
   "metadata": {
    "id": "0mHMISf4Ctpm"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 모델 생성 및 학습\n"
   ],
   "metadata": {
    "id": "oSNZ9Wha-vrs"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import global_mean_pool\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "rd_seed = 42\n",
    "\n",
    "torch.manual_seed(rd_seed)\n",
    "np.random.seed(rd_seed)\n",
    "random.seed(rd_seed)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(num_node_features, 16)\n",
    "        self.conv2 = GCNConv(16, num_classes)  # 출력 레이어를 클래스 수에 맞게 변경\n",
    "        self.dropout = torch.nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = F.dropout(x, training=self.training)\n",
    "\n",
    "        x = self.conv2(x, edge_index)\n",
    "\n",
    "        x = global_mean_pool(x, data.batch)\n",
    "\n",
    "        return F.log_softmax(x, dim=1)  # 결과를 log softmax로 변환\n",
    "\n",
    "\n",
    "\n",
    "# 데이터셋 및 모델 초기화\n",
    "dataset = CPGDataset(csv_file='/content/drive/MyDrive/dataset/labelling_file_3rd.csv')\n",
    "num_node_features = dataset.wo_cpgs_df.size(1)  # 노드 피처의 차원\n",
    "num_classes = 5\n",
    "model = GCN(num_node_features=num_node_features, num_classes=num_classes).to(device)  # 클래스 수를 모델에 전달\n",
    "\n",
    "# 훈련 데이터셋과 검증 데이터셋을 Data 객체의 리스트로 변환\n",
    "train_data_list = [dataset[i] for i in range(len(dataset.train_graph_list))]\n",
    "val_data_list = [dataset[i] for i in range(len(dataset.val_graph_list))]\n",
    "\n",
    "# 훈련 데이터셋과 검증 데이터셋에 대한 DataLoader 생성\n",
    "train_loader = DataLoader(train_data_list, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_data_list, batch_size=64, shuffle=False)\n",
    "\n",
    "# 손실 함수 및 옵티마이저 설정\n",
    "criterion = torch.nn.NLLLoss()  # 손실 함수를 NLLLoss로 변경\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "\n",
    "\n",
    "# 학습 루프\n",
    "epochs = 20\n",
    "model.train()\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0\n",
    "    for data in train_loader:\n",
    "        data = data.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, data.y.long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Loss: {epoch_loss/len(train_loader)}\")\n",
    "\n",
    "# 검증 데이터를 사용하여 성능 평가\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for val_data in val_loader:\n",
    "        val_data = val_data.to(device)\n",
    "        val_output = model(val_data)\n",
    "        _, predicted = torch.max(val_output.data, 1)\n",
    "        total += val_data.y.size(0)\n",
    "        correct += (predicted == val_data.y.long()).sum().item()\n",
    "\n",
    "print(f'Accuracy of the network on the test data: {100 * correct / total}%')\n"
   ],
   "metadata": {
    "id": "xPcDnsAL-j64"
   }
  }
 ]
}
